library(deSolve)
model3 <- function(t,y,parms){
with(as.list(c(y,parms)), {
dy1 = ((I2 - I3)/I1)*y[2]*y[3]
dy2 = ((I3 - I1)/I2)*y[1]*y[3]
dy3 = ((I1 - I2)/I3)*y[2]*y[1]
list(c(dy1,dy2,dy3))
})
}
yini <- c(y1 = 1, y2 = 0, y3 = 0.9)
# Constants:
parms <- c(I1 = 0.5, I2 = 2, I3 = 3)
# Independent variable:
times <- seq(0,20,0.01)
# ODE
out3 <- ode.3D()
setwd("C:/Git/MNT_ITESM_courses/1.1.Computacion_Aplicada/MidtermExam")
read.csv("Chocolate.csv")
chocolate = read.csv("Chocolate.csv")
summary(chocolate)
## Part 1
library(faraway)
data(pima)
# Exploration
summary(pima)
# Apply filter by filter
index = pima$glucose > 0
pima = pima[ index,  ]
index = pima$diastolic > 0
pima = pima[ index,  ]
index = pima$insulin > 0
pima = pima[ index,  ]
index = pima$triceps > 0
pima = pima[ index,  ]
index = pima$bmi > 0
pima = pima[ index,  ]
filteredPima = pima
# New size
dim(filteredPima) # 392 x 9
summary(filteredPima)
# Set numeric values to categoric value
filteredPima$test <- as.factor(filteredPima$test)
summary(filteredPima)
# Which linear model am I going to use?
# Logistic regression
mdl <- glm( test ~ ., data = filteredPima, family = "binomial")
summary(mdl)
mdl <- glm( test ~ glucose + bmi + diabetes + age, data = filteredPima, family = "binomial")
summary(mdl)
# Lets see the performance of our beta coefficients
predicted <- predict(mdl, filteredPima[,-9], type = "response")
hist(predicted)
predicted <- ifelse(predicted < 0.5, "0", "1")
predicted.table = table("Real" = filteredPima[,9], "Predicted" = predicted)
print(predicted.table)
# Prediction Power
print(sum(diag(predicted.table))/sum(predicted.table))
## Part 2
data("teengamb")
head(teengamb)
summary(teengamb)
# ANCOVA regression
teengamb$sex <- as.factor(teengamb$sex)
summary(teengamb)
# Lets create our inependent variable matrix and dependent variable vector
X <- model.matrix( ~  sex + status + income + verbal, data=teengamb )
y <- teengamb$gamble
# First formula
beta <- solve( t(X) %*% X) %*% t(X) %*% y
# Estimates
yhat <- X %*% beta
error <- y - yhat
# Residual Sum of Squares
RSS <- t(error) %*% error
# R-squared
numerator = sum( ( yhat - y)^2 )
denominator = sum( ( y - mean(y))^2 )
R.squared = 1 - numerator/denominator
# Using R function
mdl <- lm( gamble ~ . , data=teengamb)
summary(mdl)
# Lets compare
print(beta)
# Using R function
mdl <- lm( gamble ~ . , data=teengamb)
summary(mdl)
# Lets compare
print(beta)
print(RSS)
print(R.squared)
?mdl
?glm
# First we define a variable to call for the database to be analized:
chocolate = read.csv("Chocolate.csv")
head(chocolate)
# First we define a variable to call for the database to be analized:
choco_data = read.csv("Chocolate.csv")
head(chocolate)
# First we define a variable to call for the database to be analized:
choco_data = read.csv("Chocolate.csv")
head(choco_data)
summary(choco_data)
## Part 1
library(faraway)
data(pima)
# Exploration
summary(pima)
# Apply filter by filter
index = pima$glucose > 0
pima = pima[ index,  ]
index = pima$diastolic > 0
pima = pima[ index,  ]
index = pima$insulin > 0
pima = pima[ index,  ]
index = pima$triceps > 0
pima = pima[ index,  ]
index = pima$bmi > 0
pima = pima[ index,  ]
filteredPima = pima
# New size
dim(filteredPima) # 392 x 9
summary(filteredPima)
# Set numeric values to categoric value
filteredPima$test <- as.factor(filteredPima$test)
summary(filteredPima)
# Which linear model am I going to use?
# Logistic regression
mdl <- glm( test ~ ., data = filteredPima, family = "binomial")
summary(mdl)
# First we define a variable to call for the database to be analized:
choco_data = read.csv("Chocolate.csv")
head(choco_data) # Verifying there is no repeated information.
summary(choco_data)
mdl <- glm(formula = chocolate ~ ., family = "binomial", data = choco_data)
summary(mdl)
View(choco_data)
View(choco_data)
# First we define a variable to call for the database to be analized:
choco_data = read.csv("Chocolate.csv")
head(choco_data) # Verifying there is no repeated information.
# First we define a variable to call for the database to be analized:
choco_data = read.csv("Chocolate.csv")
head(choco_data) # Verifying there is no repeated information.
summary(choco_data) # Exploring the data.
# Filtering our data in order to concentrate in our dependent variable: "Chocolate":
index <- choco_data$chocolate > 0
filteredData <- choco_data[index,]
filteredData
mdl <- glm(formula = chocolate ~ ., family = "binomial", data = choco_data)
mdl <- glm(formula = chocolate ~ ., family = "binomial", data = filteredData)
summary(mdl)
hist(filteredData)
# Do a regression analysis to the "pima" dataset from the "faraway"
# library
library(faraway)
library(caret)
data(pima)
# * Analyze the database and select only the observations with no missing
#   data
# complete.cases() returns a logical vector with the value TRUE for rows that are complete, and FALSE for rows that have some NA values
completeData = complete.cases(pima)
# remove rows with incomplete data
mydata = pima[completeData, ]
# remove rows containing zeros
filter <- with(mydata,
glucose   > 0 &
diastolic > 0 &
triceps   > 0 &
insulin   > 0 &
bmi       > 0)
mydata <- mydata[filter,]
#Let's take a look to the data ...
str(mydata)
pairs(mydata)
cor(mydata)
summary(mydata)
#LOGISTIC REGRESSION
glmFitModel <- glm(test ~ pregnant + glucose + diastolic + triceps + insulin + bmi + diabetes + age, data = mydata)
summary(glmFitModel)
# First we define a variable to call for the database to be analized:
choco_data = read.csv("Chocolate.csv")
head(choco_data) # Verifying there is no repeated information.
str(choco_data) # Exploring the data.
mdl <- glm(formula = chocolate ~ fruity + caramel +  peanutyalmondy + nougat + crispedricewafer + hard + bar + pluribus + sugarpercent + pricepercent + winpercent, family = "binomial", data = filteredData)
mdl <- glm(formula = chocolate ~ fruity + caramel +  peanutyalmondy + nougat + crispedricewafer + hard + bar + pluribus + sugarpercent + pricepercent + winpercent, data = filteredData)
# First we define a variable to call for the database to be analized:
choco_data = read.csv("Chocolate.csv")
str(choco_data) # Verifying there is no repeated information.
summary(choco_data) # Exploring the data.
# Filtering our data in order to concentrate in our dependent variable: "Chocolate":
index <- choco_data$chocolate > 0
filteredData <- choco_data[index,]
mdl <- glm(formula = chocolate ~ fruity + caramel +  peanutyalmondy + nougat + crispedricewafer + hard + bar + pluribus + sugarpercent + pricepercent + winpercent, data = filteredData)
summary(mdl)
## Part 2
data("teengamb")
head(teengamb)
summary(teengamb)
# ANCOVA regression
teengamb$sex <- as.factor(teengamb$sex)
summary(teengamb)
# Lets create our inependent variable matrix and dependent variable vector
X <- model.matrix( ~  sex + status + income + verbal, data=teengamb )
y <- teengamb$gamble
# First formula
beta <- solve( t(X) %*% X) %*% t(X) %*% y
# Estimates
yhat <- X %*% beta
error <- y - yhat
# Residual Sum of Squares
RSS <- t(error) %*% error
# R-squared
numerator = sum( ( yhat - y)^2 )
denominator = sum( ( y - mean(y))^2 )
R.squared = 1 - numerator/denominator
# Using R function
mdl <- lm( gamble ~ . , data=teengamb)
summary(mdl)
# Lets compare
print(beta)
print(RSS)
print(R.squared)
# There is no need to filter our data since all variables are categorical, with the exceptions of "sugarpercent", "pricepercent" and "winpercent" but none of them have any row with a value of 0.
?boxplot
boxplot(~chocolate, data = choco_data)
# First we define a variable to call for the database to be analized:
choco_data = read.csv("Chocolate.csv")
str(choco_data) # Verifying there is no repeated information.
summary(choco_data) # Exploring the data.
# There is no need to filter our data since all variables are categorical, with the exceptions of "sugarpercent", "pricepercent" and "winpercent" but none of them have any row with a value of 0.
?boxplot
boxplot(~chocolate, data = choco_data)
# First we define a variable to call for the database to be analized:
choco_data = read.csv("Chocolate.csv")
str(choco_data) # Verifying there is no repeated information.
summary(choco_data) # Exploring the data.
mdl <- glm(formula = chocolate ~ fruity + caramel +  peanutyalmondy + nougat + crispedricewafer + hard + bar + pluribus + sugarpercent + pricepercent + winpercent, data = filteredData)
mdl <- glm(formula = chocolate ~ fruity + caramel +  peanutyalmondy + nougat + crispedricewafer + hard + bar + pluribus + sugarpercent + pricepercent + winpercent, data = choco_data)
summary(mdl) # Visualizing the model to determine the most significant variables.
# Do a regression analysis to the "pima" dataset from the "faraway"
# library
library(faraway)
library(caret)
data(pima)
# * Analyze the database and select only the observations with no missing
#   data
# complete.cases() returns a logical vector with the value TRUE for rows that are complete, and FALSE for rows that have some NA values
completeData = complete.cases(pima)
# remove rows with incomplete data
mydata = pima[completeData, ]
# remove rows containing zeros
filter <- with(mydata,
glucose   > 0 &
diastolic > 0 &
triceps   > 0 &
insulin   > 0 &
bmi       > 0)
mydata <- mydata[filter,]
#Let's take a look to the data ...
str(mydata)
pairs(mydata)
cor(mydata)
summary(mydata)
hist(choco_data)
?hist
# First we define a variable to call for the database to be analized:
choco_data = read.csv("Chocolate.csv")
str(choco_data) # Verifying there is no repeated information.
summary(choco_data) # Exploring the data.
mdl <- glm(chocolate ~ fruity + caramel +  peanutyalmondy + nougat + crispedricewafer + hard + bar + pluribus + sugarpercent + pricepercent + winpercent, data = choco_data, family = "binomial")
summary(mdl) # Visualizing the model to determine the most significant variables.
mdl <- glm.fit(chocolate ~ fruity + caramel +  peanutyalmondy + nougat + crispedricewafer + hard + bar + pluribus + sugarpercent + pricepercent + winpercent, data = choco_data, family = "binomial")
## Part 1
library(faraway)
data(pima)
# Exploration
summary(pima)
# Apply filter by filter
index = pima$glucose > 0
pima = pima[ index,  ]
index = pima$diastolic > 0
pima = pima[ index,  ]
index = pima$insulin > 0
pima = pima[ index,  ]
index = pima$triceps > 0
pima = pima[ index,  ]
index = pima$bmi > 0
pima = pima[ index,  ]
filteredPima = pima
# New size
dim(filteredPima) # 392 x 9
summary(filteredPima)
# Set numeric values to categoric value
filteredPima$test <- as.factor(filteredPima$test)
summary(filteredPima)
# Which linear model am I going to use?
# Logistic regression
mdl <- glm( test ~ ., data = filteredPima, family = "binomial")
summary(mdl)
mdl <- glm( test ~ glucose + bmi + diabetes + age, data = filteredPima, family = "binomial")
summary(mdl)
# First we define a variable to call for the database to be analized:
choco_data = read.csv("Chocolate.csv")
str(choco_data) # Verifying there is no repeated information.
summary(choco_data) # Exploring the data.
# Since the dependent variable "Chocolate" is a categorical variable, we have decided to use Logistic Regression:
mdl <- glm(chocolate ~ ., data = choco_data, family = "binomial")
summary(mdl)
mdl <- glm(chocolate ~ fruity + caramel +  peanutyalmondy + nougat + crispedricewafer + hard + bar + pluribus + sugarpercent + pricepercent + winpercent, data = choco_data, family = "binomial")
summary(mdl) # Visualizing the model to determine the most significant variables.
# Lets see the performance of our beta coefficients:
predicted <- predict(mdl, choco_data[,-9], type = "response")
# First we define a variable to call for the database to be analized:
choco_data = read.csv("Chocolate.csv")
str(choco_data) # Verifying there is no repeated information.
summary(choco_data) # Exploring the data.
# First we define a variable to call for the database to be analized:
choco_data = read.csv("Chocolate.csv")
str(choco_data) # Verifying there is no repeated information.
summary(choco_data) # Exploring the data.
# Since the dependent variable "Chocolate" is a categorical variable, we have decided to use Logistic Regression:
mdl <- glm(chocolate ~ ., data = choco_data, family = "binomial")
summary(mdl)
# First we define a variable to call for the database to be analized:
choco_data = read.csv("Chocolate.csv")
str(choco_data) # Verifying there is no repeated information.
summary(choco_data) # Exploring the data.
# Set numeric values to categoric value
choco_data$chocolate <- as.factor(choco_data$chocolate)
summary(choco_data)
# First we define a variable to call for the database to be analized:
choco_data = read.csv("Chocolate.csv")
str(choco_data) # Verifying there is no repeated information.
summary(choco_data) # Exploring the data.
# Set numeric values to categoric value
choco_data$chocolate <- as.factor(choco_data$chocolate)
summary(choco_data)
# Since the dependent variable "Chocolate" is a categorical variable, we have decided to use Logistic Regression:
mdl <- glm(chocolate ~ ., data = choco_data, family = "binomial")
summary(mdl)
mdl <- glm(chocolate ~ fruity + caramel +  peanutyalmondy + nougat + crispedricewafer + hard + bar + pluribus + sugarpercent + pricepercent + winpercent, data = choco_data, family = "binomial")
summary(mdl) # Visualizing the model to determine the most significant variables.
## Part 1
library(faraway)
data(pima)
# Exploration
summary(pima)
# Apply filter by filter
index = pima$glucose > 0
pima = pima[ index,  ]
index = pima$diastolic > 0
pima = pima[ index,  ]
index = pima$insulin > 0
pima = pima[ index,  ]
# Setting numeric values to categoric value:
choco_data$chocolate <- as.factor(choco_data$chocolate)
summary(choco_data)
?factor
?levels()
?labels()
?label()
mdl <- glm(chocolate ~ competitorname +fruity + caramel +  peanutyalmondy + nougat + crispedricewafer + hard + bar + pluribus + sugarpercent + pricepercent + winpercent, data = choco_data, family = "binomial")
summary(mdl) # Visualizing the model to determine the most significant variables.
# First we define a variable to call for the database to be analized:
choco_data = read.csv("Chocolate.csv")
str(choco_data) # Verifying there is no repeated information.
summary(choco_data) # Exploring the data.
chocolate_labels <- choco_data[,1]
# Setting numeric values to categoric value:
choco_data$chocolate <- as.factor(choco_data$chocolate)
summary(choco_data)
# First we define a variable to call for the database to be analized:
choco_data = read.csv("Chocolate.csv")
str(choco_data) # Verifying there is no repeated information.
summary(choco_data) # Exploring the data.
chocolate_labels <- choco_data[,1]
choco_data <- choco_data[,-1]
# Setting numeric values to categoric value:
choco_data$chocolate <- as.factor(choco_data$chocolate)
summary(choco_data)
# Since the dependent variable "Chocolate" is a categorical variable, we have decided to use Logistic Regression:
mdl <- glm(chocolate ~ ., data = choco_data, family = "binomial")
summary(mdl)
mdl <- glm(chocolate ~ fruity + caramel +  peanutyalmondy + nougat + crispedricewafer + hard + bar + pluribus + sugarpercent + pricepercent + winpercent, data = choco_data, family = "binomial")
summary(mdl) # Visualizing the model to determine the most significant variables.
# Lets see the performance of our beta coefficients:
predicted <- predict(mdl, choco_data[,], type = "response")
hist(predicted)
# First we define a variable to call for the database to be analized:
choco_data = read.csv("Chocolate.csv")
str(choco_data) # Verifying there is no repeated information.
summary(choco_data) # Exploring the data.
chocolate_labels <- choco_data[,1]
choco_data <- choco_data[,-1]
# Setting numeric values to categoric value:
choco_data$chocolate <- as.factor(choco_data$chocolate)
summary(choco_data)
# Since the dependent variable "Chocolate" is a categorical variable, we have decided to use Logistic Regression:
mdl <- glm(chocolate ~ ., data = choco_data, family = "binomial")
summary(mdl)
mdl <- glm(chocolate ~ fruity + caramel +  peanutyalmondy + nougat + crispedricewafer + hard + bar + pluribus + sugarpercent + pricepercent + winpercent, data = choco_data, family = "binomial")
summary(mdl) # Visualizing the model to determine the most significant variables.
# Lets see the performance of our beta coefficients:
predicted <- predict(mdl, choco_data[,], type = "response")
hist(predicted)
mdl <- glm(chocolate ~ fruity + winpercent, data = choco_data, family = "binomial")
summary(mdl) # Visualizing the model to determine the most significant variables.
mdl <- glm(chocolate ~ fruity + caramel +  peanutyalmondy + nougat + crispedricewafer + hard + bar + pluribus + sugarpercent + pricepercent + winpercent, data = choco_data, family = "binomial")
summary(mdl) # Visualizing the model to determine the most significant variables.
mdl <- glm(chocolate ~ fruity + winpercent, data = choco_data, family = "binomial")
summary(mdl) # Visualizing the model to determine the most significant variables.
# Lets see the performance of our beta coefficients:
predicted <- predict(mdl, choco_data[,], type = "response")
hist(predicted)
#We assume that: all values less than 0.5 correspond to the first category, 0.5 or bigger correspond to the second category
glm_predicted = ifelse(predicted > 0.5, 1, 0)
hist(glm_predicted)
