---
title: "Sentiment Analysis"
author: "Antonio Osamu Katagiri Tanaka - A01212611@itesm.mx"
date: "May 01, 2020"
output:
  pdf_document: default
  html_notebook: default
  word_document: default
  html_document:
    df_print: paged
geometry: margin=1.75cm
classoption: a4paper
always_allow_html: yes
---

# Part 1: paper mining

## Load libraries and set custom settings

```{r}
# Clear all objects (from the workspace)
rm(list = ls())

# Strings are not factors
options(stringsAsFactors = F)

# Install and load libraries
library(RISmed)
library(tm)
```

## Define the requested query and seek

```{r}
query_colon <-
    "\"electrospinning\"[TIAB] AND (\"NFES\"[TIAB] OR (\"near\"[TIAB] AND \"field\"[TIAB]))"
search_query <- EUtilsSummary(query_colon)

# Let's take a look
summary(search_query)
```

## Fetch the data as dataframes

```{r}
records <- EUtilsGet(search_query)
pubmed_data <-
    data.frame(
        'Title' = ArticleTitle(records),
        'Abstract' = AbstractText(records),
        'PID' = ArticleId(records)
    )

# Let's take a look to the 1st search
pubmed_data[1, ]
```

## Process the data

```{r}
# Remove characters : , ; [ ] ( ) from titles and abstracts
pubmed_data$Title <-
    gsub(pattern = "\\.|:|,|;|\\[|\\]|\\(|\\)|-",
         replacement = "",
         pubmed_data$Title)
pubmed_data$Abstract <-
    gsub(pattern = "\\.|:|,|;|\\[|\\]|\\(|\\)|-",
         replacement = "",
         pubmed_data$Abstract)

# Remove upper case in titles and abstracts
pubmed_data$Title <- tolower(pubmed_data$Title)
pubmed_data$Abstract <- tolower(pubmed_data$Abstract)

# Let's take a look to the 1st search
pubmed_data[1, ]
```

```{r}
# Are there empty abstracts?
which(pubmed_data$Abstract == "")
```

```{r}
# Fetch the words within all abstracts in a dataframe.

# data frame para guardar las palabras
word_list <- c()

#Ciclo para todos los abstracts
for (i in 1:length(pubmed_data$Abstract)) {
    #Obtener las palabras como vector en lugar de lista
    titlePabstract <- paste(pubmed_data$Title[i], pubmed_data$Abstract[i], sep = " ")
    aux_word <- unlist(strsplit(titlePabstract, " "))
    #aux_word <- unlist(strsplit(pubmed_data$Abstract[i], " "))
    
    #Si el abstract tiene palabras
    if (length(aux_word) > 0) {
        #Se juntan las palabras y el PUBMED ID
        aux_list <- cbind(pubmed_data$PID[i], aux_word)
        
        #Se pega este data frame auxiliar al que guarda todo
        word_list <- rbind(word_list, aux_list)
    }
}
colnames(word_list) <- c("PID", "Word")

# Let's take a look
dim(word_list)
```

```{r}
# Let's take a look
head(word_list)
```

```{r}
# Remove stopwords with tm

# Fetch the English stop_words from tm DB
stop_words <- stopwords(kind = "en")
head(stop_words)

# Use the indexes to remove stopwords
index_stop_word <- which(word_list[, 2] %in% stop_words)

# Let's take a look
dim(word_list)

word_list <- word_list[-index_stop_word, ]

# Let's take a look
dim(word_list)
```

```{r}
# Show the 10 most popular words
sort(table(word_list[,2]), decreasing=T)[1:10]
```

```{r}
# Remove duplicated words within each abstract

# Identify each word's abstract origin
word_df <- data.frame(PID=as.numeric(word_list[,1]), Word=word_list[,2],
PIDWord=as.character(apply(word_list, 1, paste, collapse="_")))

# Remove duplicates
dup_index <- duplicated(word_df$PIDWord)
dim(word_df) # Let's take a look
word_df <- word_df[-which(dup_index),]

# Let's take a look
dim(word_df)
```

```{r}
# Show the 50 most popular words (no duplicates)
sort(table(word_df$Word), decreasing=T)[1:50]
```

## Let's take a look to specific words

```{r}
word_df <- word_df[order(word_df$PID, decreasing=T),]
index_genes <- which(word_df$Word %in% c("pyrolysis", "carbon", "conductivity"))

# Let's take a look
word_df[index_genes, c("PID","Word")]
```

# Part 2: COVID-19 Public Sentiment Analysis

Text sentiment analyses can be implemented in the identification of misinformation on social media during the coronavirus pandemic. It could be possible to analyse an extensive number of tweets to determine how false information about the coronavirus spreads on social media. Concerns include statements from about hot water eliminating the virus to deceits about past quarantines. While we are trying to contain the virus' spread, misinformation could drain critical resources and set potentially dangerous distractions. Social media has a strong impact in communication during global crisis. Exposing false, misleading and clickbait content can provide a means to explain whether social media can provide insights into social behaviours in real time.