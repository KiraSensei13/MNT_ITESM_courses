{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WHO API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"error\":false,\"statusCode\":200,\"message\":\"OK\",\"data\":{\"lastChecked\":\"2020-04-26T19:22:09.435Z\",\"covid19Stats\":[{\"city\":null,\"province\":null,\"country\":\"Mexico\",\"lastUpdate\":\"2020-04-26T02:30:31+00:00\",\"keyId\":\"Mexico\",\"confirmed\":13842,\"deaths\":1305,\"recovered\":7149}]}}\n"
     ]
    }
   ],
   "source": [
    "import requests;\n",
    "\n",
    "url     = \"https://covid-19-coronavirus-statistics.p.rapidapi.com/v1/stats\";\n",
    "query   = {\"country\":\"Mexico\"};\n",
    "headers = {\n",
    "    'x-rapidapi-host': \"covid-19-coronavirus-statistics.p.rapidapi.com\",\n",
    "    'x-rapidapi-key': \"7e6cf1dbafmsha291e24ccb65407p1469b1jsn307b9be6aeef\"\n",
    "};\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers, params=query);\n",
    "print(response.text);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### https://www.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'Our World in Data' data compilation\n",
    "#### Sourced from the World Health Organization (WHO) Situation Reports\n",
    "##### https://ourworldindata.org/coronavirus\n",
    "##### https://ourworldindata.org/coronavirus-source-data; https://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases\n",
    "##### https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reports/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting up tqdm\n",
    "```python\n",
    "pip install ipywidgets \n",
    "jupyter nbextension enable --py widgetsnbextension\n",
    "jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tqdm().pandas()\n",
    "# Activate tqdm in a notebook [https://towardsdatascience.com/progress-bars-in-python-4b44e8a4c482]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CONFIRMED'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>4/16/20</th>\n",
       "      <th>4/17/20</th>\n",
       "      <th>4/18/20</th>\n",
       "      <th>4/19/20</th>\n",
       "      <th>4/20/20</th>\n",
       "      <th>4/21/20</th>\n",
       "      <th>4/22/20</th>\n",
       "      <th>4/23/20</th>\n",
       "      <th>4/24/20</th>\n",
       "      <th>4/25/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>840</td>\n",
       "      <td>906</td>\n",
       "      <td>933</td>\n",
       "      <td>996</td>\n",
       "      <td>1026</td>\n",
       "      <td>1092</td>\n",
       "      <td>1176</td>\n",
       "      <td>1279</td>\n",
       "      <td>1351</td>\n",
       "      <td>1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.1533</td>\n",
       "      <td>20.1683</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>518</td>\n",
       "      <td>539</td>\n",
       "      <td>548</td>\n",
       "      <td>562</td>\n",
       "      <td>584</td>\n",
       "      <td>609</td>\n",
       "      <td>634</td>\n",
       "      <td>663</td>\n",
       "      <td>678</td>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.0339</td>\n",
       "      <td>1.6596</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2268</td>\n",
       "      <td>2418</td>\n",
       "      <td>2534</td>\n",
       "      <td>2629</td>\n",
       "      <td>2718</td>\n",
       "      <td>2811</td>\n",
       "      <td>2910</td>\n",
       "      <td>3007</td>\n",
       "      <td>3127</td>\n",
       "      <td>3256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.5063</td>\n",
       "      <td>1.5218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>673</td>\n",
       "      <td>696</td>\n",
       "      <td>704</td>\n",
       "      <td>713</td>\n",
       "      <td>717</td>\n",
       "      <td>717</td>\n",
       "      <td>723</td>\n",
       "      <td>723</td>\n",
       "      <td>731</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Angola</td>\n",
       "      <td>-11.2027</td>\n",
       "      <td>17.8739</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region      Lat     Long  1/22/20  1/23/20  1/24/20  \\\n",
       "0            NaN    Afghanistan  33.0000  65.0000        0        0        0   \n",
       "1            NaN        Albania  41.1533  20.1683        0        0        0   \n",
       "2            NaN        Algeria  28.0339   1.6596        0        0        0   \n",
       "3            NaN        Andorra  42.5063   1.5218        0        0        0   \n",
       "4            NaN         Angola -11.2027  17.8739        0        0        0   \n",
       "\n",
       "   1/25/20  1/26/20  1/27/20  ...  4/16/20  4/17/20  4/18/20  4/19/20  \\\n",
       "0        0        0        0  ...      840      906      933      996   \n",
       "1        0        0        0  ...      518      539      548      562   \n",
       "2        0        0        0  ...     2268     2418     2534     2629   \n",
       "3        0        0        0  ...      673      696      704      713   \n",
       "4        0        0        0  ...       19       19       24       24   \n",
       "\n",
       "   4/20/20  4/21/20  4/22/20  4/23/20  4/24/20  4/25/20  \n",
       "0     1026     1092     1176     1279     1351     1463  \n",
       "1      584      609      634      663      678      712  \n",
       "2     2718     2811     2910     3007     3127     3256  \n",
       "3      717      717      723      723      731      738  \n",
       "4       24       24       25       25       25       25  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-323a4af4a5c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[0murl_deaths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://data.humdata.org/hxlproxy/api/data-preview.csv?url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_deaths_global.csv&filename=time_series_covid19_deaths_global.csv\"\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m \u001b[0mdf_deaths_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_deaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DEATHS\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_deaths_raw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[1;31m# See https://github.com/python/mypy/issues/1297\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m     fp_or_buf, _, compression, should_close = get_filepath_or_buffer(\n\u001b[1;32m--> 431\u001b[1;33m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m     )\n\u001b[0;32m    433\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m         \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Content-Encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"gzip\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[1;32m--> 543\u001b[1;33m                                   '_open', req)\n\u001b[0m\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[1;32m-> 1362\u001b[1;33m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[0;32m   1363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m             \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1342\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1344\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1345\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1069\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1071\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    927\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 929\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    930\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# PYTHON LIBRARIES\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dateparser\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from adjustText import adjust_text\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "number = LabelEncoder()\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
    "matplotlib_axes_logger.setLevel('ERROR')\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from scipy import signal\n",
    "\n",
    "# CONSTANTS\n",
    "markerSymbol = [\n",
    "    \"o\", #circle\n",
    "    \"v\", #triangle_down\n",
    "    \"^\", #triangle_up\n",
    "    \"<\", #triangle_left\n",
    "    \">\", #triangle_right\n",
    "    \"s\", #square\n",
    "    \"p\", #pentagon\n",
    "    \"P\", #plus (filled)\n",
    "    \"*\", #star\n",
    "    \"H\", #hexagon2\n",
    "    \"X\", #x (filled)\n",
    "    \"D\", #diamond\n",
    "    \"d\", #thin_diamond\n",
    "    \"1\", #tri_down\n",
    "    \"2\", #tri_up\n",
    "    \"3\", #tri_left\n",
    "    \"4\", #tri_right\n",
    "    \"+\", #plus\n",
    "    \"x\"  #x\n",
    "];\n",
    "\n",
    "markerColour = [\n",
    "    '#9e9e9e', #grey\n",
    "    '#e91e63', #pink\n",
    "    '#9c27b0', #purple\n",
    "    '#673ab7', #deep-purple\n",
    "    '#3f51b5', #indigo\n",
    "    '#2196f3', #blue\n",
    "    '#03a9f4', #light-blue\n",
    "    '#00bcd4', #cyan\n",
    "    '#009688', #teal\n",
    "    '#4caf50', #green\n",
    "    '#8bc34a', #light-green\n",
    "    '#cddc39', #lime\n",
    "    '#ffeb3b', #yellow\n",
    "    '#ffc107', #amber\n",
    "    '#ff9800', #orange\n",
    "    '#ff5722', #deep-orange\n",
    "    '#795548', #brown\n",
    "    '#f44336'  #red\n",
    "];\n",
    "\n",
    "# df.loc[<ROWS RANGE> , <COLUMNS RANGE>] to get elements by index\n",
    "\n",
    "# https://vac-lshtm.shinyapps.io/ncov_tracker/\n",
    "url_confirmed = \"https://data.humdata.org/hxlproxy/api/data-preview.csv?url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_confirmed_global.csv&filename=time_series_covid19_confirmed_global.csv\";\n",
    "df_confirmed_raw = pd.read_csv(url_confirmed, delimiter=\",\");\n",
    "display(\"CONFIRMED\", df_confirmed_raw.head())\n",
    "\n",
    "url_deaths = \"https://data.humdata.org/hxlproxy/api/data-preview.csv?url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_deaths_global.csv&filename=time_series_covid19_deaths_global.csv\";\n",
    "df_deaths_raw = pd.read_csv(url_deaths, delimiter=\",\");\n",
    "display(\"DEATHS\", df_deaths_raw.head())\n",
    "\n",
    "url_recovered = \"https://data.humdata.org/hxlproxy/api/data-preview.csv?url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_recovered_global.csv&filename=time_series_covid19_recovered_global.csv\";\n",
    "df_recovered_raw = pd.read_csv(url_recovered, delimiter=\",\");\n",
    "display(\"RECOVERED\", df_recovered_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinstr(x):\n",
    "    if x != '': return ' - ';\n",
    "    else:       return '';\n",
    "\n",
    "def formatdate(x):\n",
    "    res = x.split('/')\n",
    "    res[0] = \"%02d\" % (int(res[0]),); # month\n",
    "    res[1] = \"%02d\" % (int(res[1]),); # day\n",
    "    res[2] = res[2]; # year\n",
    "    return('-'.join(res));\n",
    "\n",
    "def explodeDF(df_raw):\n",
    "    # Remove NANs\n",
    "    df_raw = df_raw.replace(np.nan, '');\n",
    "\n",
    "    # Concatenate \"Country/Region\" & \"Province/State\" tp make the location column\n",
    "    df_raw['Location'] = df_raw[[\"Country/Region\", \"Province/State\"]].apply(\n",
    "        # Add a \" - \" if the \"Province/State\" exists \n",
    "        lambda x: joinstr(x[\"Province/State\"]).join(x), axis=1\n",
    "    );\n",
    "\n",
    "    # Remove unnecessary columns\n",
    "    df_raw = df_raw.drop(columns=['Lat', 'Long', 'Province/State', 'Country/Region']);\n",
    "\n",
    "    # Make the \"Location\" column to be the first column\n",
    "    location = df_raw['Location'];\n",
    "    df_raw.drop(labels=['Location'], axis=1,inplace = True);\n",
    "    df_raw.insert(0, 'Location', location);\n",
    "    \n",
    "#     # let's take a look to the data\n",
    "#     display(\"PROCESSED DATA\", df_raw.head());\n",
    "\n",
    "    # Build the plotable df\n",
    "    date     = list(df_raw.columns);\n",
    "    location = list(df_raw['Location']);\n",
    "    df       = pd.DataFrame(columns=[\"Location\", \"date\", \"counts\"]);\n",
    "    \n",
    "    # Explode the data frame\n",
    "#     for i in range(len(location)):\n",
    "    for i in tqdm(range(len(location))):\n",
    "        for j in range(len(date)):\n",
    "            if j > 0:\n",
    "                df = df.append({\n",
    "                    \"Location\": location[i],\n",
    "                    \"date\":     date[j],\n",
    "                    \"counts\":   df_raw[date[j]][i]\n",
    "                }, ignore_index=True);\n",
    "                \n",
    "    # Sum all Provinces/States of one country\n",
    "    # Get countries that are divided into several Provinces/States\n",
    "    allcountries = location\n",
    "    dividedCountries = [];\n",
    "    for location in allcountries:\n",
    "        if \" - \" in location:\n",
    "            country = location.split(\" - \")[0]\n",
    "            if not(country in dividedCountries) and not(country in allcountries):\n",
    "                dividedCountries.append(country)\n",
    "\n",
    "#     # Let's take a look\n",
    "#     display(dividedCountries)\n",
    "    \n",
    "    for country in dividedCountries:\n",
    "        # Get rows that contain a specific country\n",
    "        row = df_raw[df_raw['Location'].str.contains(country)]\n",
    "\n",
    "        # Get totals for each date (column)\n",
    "        row = pd.DataFrame(row.sum())\n",
    "\n",
    "        # Add a column containing the dates\n",
    "        row['date'] = date\n",
    "        \n",
    "        # Remove the first row, generated by .sum()\n",
    "        row = row.drop('Location')\n",
    "        \n",
    "        # Add a column containing the country name\n",
    "        row['Location'] = [country] * len(row)\n",
    "        \n",
    "        # Remane the '0' column as it contains the totals, calculated by .sum()\n",
    "        row = row.rename(columns={0: \"counts\"})\n",
    "        \n",
    "        # Reorder the columns to match the previous data\n",
    "        row = row[['Location','date','counts']]\n",
    "        \n",
    "        # Append the calculated totals to the existing data\n",
    "        df = df.append(row);\n",
    "        \n",
    "        # Give each row a unique index/ID. df.index = range(len(df.index))\n",
    "        df.index = df[[\"Location\", \"date\"]].apply(\n",
    "            # Add a \" - \" if the \"Province/State\" exists\n",
    "            lambda x: joinstr(x[\"Location\"]).join(x), axis=1\n",
    "        );\n",
    "\n",
    "#         # Let's take a look\n",
    "#         display(row.head())\n",
    "\n",
    "#     # let's take a look to the data\n",
    "#     display(\"PROCESSED DATA\", df.head());\n",
    "#     df.to_csv(r'./_data_.csv', index = False);\n",
    "\n",
    "    return df;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Make data.csv ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the original data\n",
    "print(\"Exploding confirmed cases ...\");\n",
    "df_confirmed_explode = explodeDF(df_confirmed_raw);\n",
    "print(\"Exploding deaths ...\");\n",
    "df_deaths_explode    = explodeDF(df_deaths_raw);\n",
    "print(\"Exploding recovered cases ...\");\n",
    "df_recovered_explode = explodeDF(df_recovered_raw);\n",
    "\n",
    "# # let's take a look to the data\n",
    "# df_confirmed_explode.to_csv(r'./df_confirmed_explode.csv', index = False);\n",
    "# df_deaths_explode.to_csv(r'./df_deaths_explode.csv', index = False);\n",
    "# df_recovered_explode.to_csv(r'./df_recovered_explode.csv', index = False);\n",
    "# display(\"PROCESSED DATA\", df_confirmed_explode.head());\n",
    "# display(\"PROCESSED DATA\", df_deaths_explode.head());\n",
    "# display(\"PROCESSED DATA\", df_recovered_explode.head());\n",
    "\n",
    "# Build the plotable dataframe with columns from several datasets\n",
    "print(\"Building the dataset ...\");\n",
    "df_raw = pd.DataFrame();\n",
    "df_raw = pd.concat([df_raw, df_confirmed_explode['Location']], axis=1, sort=False)\n",
    "df_raw = pd.concat([df_raw, df_confirmed_explode['date']], axis=1, sort=False)\n",
    "df_raw = pd.concat([df_raw, df_confirmed_explode['counts']], axis=1, sort=False)\n",
    "df_raw = df_raw.rename(columns={\"counts\": \"confirmed\"})\n",
    "df_raw = pd.concat([df_raw, df_deaths_explode['counts']], axis=1, sort=False)\n",
    "df_raw = df_raw.rename(columns={\"counts\": \"deaths\"})\n",
    "df_raw = pd.concat([df_raw, df_recovered_explode['counts']], axis=1, sort=False)\n",
    "df_raw = df_raw.rename(columns={\"counts\": \"recovered\"})\n",
    "\n",
    "# Build the plotable dataframe with CALCULATED columns\n",
    "# Calculate active cases\n",
    "print(\"Calculating active cases ...\")\n",
    "df_raw['active'] = df_raw['confirmed'] - df_raw['deaths'] - df_raw['recovered'];\n",
    "\n",
    "# Calculate new cases, deaths and recoveries per day\n",
    "print(\"Calculating new cases, deaths, recoveries and rate of growth per day ...\")\n",
    "df_raw['new_confirmed']   = np.NaN;\n",
    "df_raw['new_deaths']      = np.NaN;\n",
    "df_raw['new_recovered']   = np.NaN;\n",
    "df_raw['new_active']      = np.NaN;\n",
    "df_raw['rate_of_growth']  = np.NaN;\n",
    "df_raw['index_confirmed'] = np.NaN;\n",
    "df_raw['index_deaths']    = np.NaN;\n",
    "df_raw['index_recovered'] = np.NaN;\n",
    "df_raw['index_active']    = np.NaN;\n",
    "currentLocation = '';\n",
    "for i in tqdm(range(len(df_raw))):\n",
    "    if currentLocation != df_raw['Location'][i]:\n",
    "#         print(df_raw['Location'][i]);\n",
    "        currentLocation = df_raw['Location'][i];\n",
    "        count_confirmed = 0;\n",
    "        count_deaths    = 0;\n",
    "        count_recovered = 0;\n",
    "        count_active    = 0;\n",
    "        is_active       = False;\n",
    "    else:\n",
    "        df_raw['new_confirmed'][i]  = df_raw['confirmed'][i] - df_raw['confirmed'][i - 1];\n",
    "        df_raw['new_deaths'][i]     = df_raw['deaths'][i]    - df_raw['deaths'][i - 1];\n",
    "        df_raw['new_recovered'][i]  = df_raw['recovered'][i] - df_raw['recovered'][i - 1];\n",
    "        df_raw['new_active'][i]     = df_raw['active'][i]    - df_raw['active'][i - 1];\n",
    "        try:\n",
    "            df_raw['rate_of_growth'][i] = float(df_raw['active'][i] / df_raw['active'][i - 1]);\n",
    "        except ZeroDivisionError:\n",
    "            df_raw['rate_of_growth'][i] = 0;\n",
    "        \n",
    "        if (df_raw['confirmed'][i] > 1000):\n",
    "            df_raw['index_confirmed'][i] = count_confirmed;\n",
    "            count_confirmed = count_confirmed + 1;\n",
    "            \n",
    "        if (df_raw['deaths'][i] > 50):\n",
    "            df_raw['index_deaths'][i] = count_deaths;\n",
    "            count_deaths = count_deaths + 1;\n",
    "            \n",
    "        if (df_raw['recovered'][i] > 2000):\n",
    "            df_raw['index_recovered'][i] = count_recovered;\n",
    "            count_recovered = count_recovered + 1;\n",
    "            \n",
    "        if (df_raw['active'][i] > 1000): is_active = True;\n",
    "        if is_active:\n",
    "            df_raw['index_active'][i] = count_active;\n",
    "            count_active = count_active + 1;\n",
    "\n",
    "# Format the date column\n",
    "print(\"Formatting the dates ...\")\n",
    "date = list(df_raw['date'])\n",
    "date = [str(dateparser.parse(str(x))) for x in date];\n",
    "df_raw['date'] = date\n",
    "\n",
    "# Save the dataframe as CSV\n",
    "print(\"Saving CSV ...\")\n",
    "df_raw.to_csv(r'./data.csv', index = False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Load data from saved CSV to spare processing time ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_confirmed = \"./data.csv\";\n",
    "df_raw = pd.read_csv(url_confirmed, delimiter=\",\");\n",
    "\n",
    "# let's take a look to the data\n",
    "display(\"PROCESSED DATA\", df_raw.head());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://vac-lshtm.shinyapps.io/ncov_tracker/\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print all countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('; '.join(df_raw.iloc[:]['Location'].drop_duplicates().sort_values()))\n",
    "allcountries = df_raw.iloc[:]['Location'].drop_duplicates().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to plot the number of 'new_cases', 'new_deaths', 'total_cases' or 'total_deaths' per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covid19plot(x_str, y_str, countries, legPos='upper left', xlogScale=False, ylogScale=False, annotations=True, adjusttxt=True):\n",
    "    # Assign a numeric value to string data type values\n",
    "    df_num = df_raw.copy();\n",
    "    for col in range(len(df_raw.columns)):\n",
    "        if str(type(df_raw.iloc[0 , col])) == \"<class 'str'>\":\n",
    "            df_num.iloc[: , col] = number.fit_transform(df_raw.iloc[: , col].astype('str'))\n",
    "\n",
    "    # Get the string and numeric values in one df\n",
    "    df_fil = pd.DataFrame(df_raw);\n",
    "    df_fil = df_fil.join(\n",
    "        pd.DataFrame(\n",
    "            df_num.iloc[:]['Location']\n",
    "        ).rename(\n",
    "            columns={\"Location\": \"LocationID\"}\n",
    "        )\n",
    "    );\n",
    "\n",
    "    # PLOT SETUP\n",
    "    scale = 7;\n",
    "    fig   = plt.figure(figsize=(3*scale, 2*scale));\n",
    "    plt.rc('xtick', labelsize=15)\n",
    "    plt.rc('ytick', labelsize=15)\n",
    "    plt.tight_layout();\n",
    "\n",
    "    reffontsize = 16;\n",
    "\n",
    "    # Stablish the plot area\n",
    "    ax0 = plt.gca()\n",
    "\n",
    "    if xlogScale: plt.xscale('log');\n",
    "    if ylogScale: plt.yscale('log');\n",
    "\n",
    "    texts_ax0 = [];\n",
    "    for c in countries:\n",
    "        for ystr in y_str:\n",
    "            ## Remove NANs from interesting x,y data\n",
    "            #df_fil = df_fil.dropna(subset=[x_str, ystr]);\n",
    "            \n",
    "#             # Define x axis\n",
    "#             if useIndex: x_str = 'index_confirmed';\n",
    "#             else:        x_str = 'date';\n",
    "            \n",
    "            # Define y axis\n",
    "            if (ystr == 'rate_of_growth'):\n",
    "                y_units = r'$[of \\cdot active \\cdot cases]$';\n",
    "                ax0.axhline(y=1, linestyle=':', color=markerColour[0]);\n",
    "            else:                          y_units = r'$[No. cases]$';\n",
    "\n",
    "            # Extract data from a specific country\n",
    "            df_county = df_fil[df_fil.Location.isin([c])]\n",
    "            if ylogScale:\n",
    "                df_county = df_county[df_county[ystr] > 0]\n",
    "\n",
    "            x = df_county.iloc[:][x_str];\n",
    "            if x_str == 'date':\n",
    "                x = [datetime.strptime(d,\"%Y-%m-%d %H:%M:%S\").date() for d in x]\n",
    "            y = df_county.iloc[:][ystr];\n",
    "\n",
    "            # Extract country details\n",
    "            locName   = df_county.iloc[:]['Location'];\n",
    "            locColour = df_county.iloc[:]['LocationID'];\n",
    "\n",
    "            # Plot each point individually to give each a defined color according to its related polymer\n",
    "            ci_col    = 0;\n",
    "            eleCount  = 0;\n",
    "            stringCnt = '';\n",
    "            leny      = len(y);\n",
    "            try:\n",
    "                maxy = max(y);\n",
    "            except ValueError:\n",
    "                maxy = 0;\n",
    "            \n",
    "            if not(pd.Series(x).isnull().all()) and not(pd.Series(y).isnull().all()):\n",
    "                for xi, yi, ci, ni in zip(x, y, locColour, locName):\n",
    "                    # add data points\n",
    "                    ci_col = ci%len(markerColour);\n",
    "                    ci_sym = ci%len(markerSymbol);\n",
    "                    ax0.scatter(xi, yi, s=32, label=ni, c=markerColour[ci_col], marker=markerSymbol[ci_sym]);\n",
    "\n",
    "                    if annotations:\n",
    "                        # add annotations (references on each point)\n",
    "                        eleCount = eleCount + 1;\n",
    "                        if ystr != 'rate_of_growth':\n",
    "                            try:               rnd_yi = round(yi);\n",
    "                            except ValueError: rnd_yi = np.NaN;\n",
    "                        else:                        rnd_yi = round(yi, 3);\n",
    "                        if len(y_str) > 1: stryi = str(rnd_yi) + ystr + ':' + c;\n",
    "                        else:              stryi = str(rnd_yi) + ':' + c;\n",
    "                        #if ((yi==maxy) or (eleCount==len(y))) and not(stryi in stringCnt) and (yi > 0):\n",
    "                        if (eleCount==len(y)) and not(stryi in stringCnt) and (yi > 0):\n",
    "                            # Add text annotations to the axes\n",
    "                            # print(stryi)\n",
    "                            texts_ax0.append(ax0.text(xi, yi, stryi, fontsize=reffontsize));\n",
    "                            stringCnt = stringCnt + stryi + ', ';\n",
    "\n",
    "                # Plot a curve to join the data points\n",
    "                if not((x_str == 'date') or ('index' in x_str) or (x_str == 'Location')):\n",
    "                    y = signal.medfilt(y, 3);\n",
    "                plt.plot(x, y, color=markerColour[ci_col])\n",
    "\n",
    "                # Plot predictions for next active cases ...\n",
    "                if ystr == 'active':\n",
    "                    # Get rate_of_growth\n",
    "                    df_raw_r    = df_county['rate_of_growth'];                    # Country rate_of_growth Dataframe\n",
    "                    df_raw_li   = df_raw_r.index[len(df_raw_r)-1];                # Country last Dataframe index\n",
    "                    df_raw_lten = df_raw_r.index[len(df_raw_r)-3:len(df_raw_r)];  # Country last 15 Dataframe indexes\n",
    "                    rog         = df_raw_r[df_raw_lten].mean();                   # Country rate_of_growth\n",
    "                    # Get timestamp\n",
    "                    if x_str == 'date':\n",
    "                        tim = [x[len(x)-1]]\n",
    "                    else:\n",
    "                        df_raw_a = df_county[x_str];      # Country time Dataframe\n",
    "                        tim      = [df_raw_a[df_raw_li]]; # Country timestamp\n",
    "                    # Get active cases\n",
    "                    df_raw_a  = df_county['active'];   # Country active Dataframe\n",
    "                    act       = [df_raw_a[df_raw_li]]; # Country active cases\n",
    "                    # Plot 5 day prediction (and add annotations)\n",
    "                    for i in range(5):\n",
    "                        if x_str == 'date': tim.append(tim[i] + timedelta(days=1))\n",
    "                        else:               tim.append(tim[i] + 1)\n",
    "                        act.append(act[i]*rog)\n",
    "                    plt.plot(tim, act, color=markerColour[ci_col], linestyle=':')\n",
    "                    texts_ax0.append(ax0.text(tim[len(tim)-1], act[len(act)-1], str(round(act[len(act)-1])) + ':' + c, fontsize=reffontsize-5));\n",
    "                    \n",
    "    # avoid overlaps between annotations and add a linking line\n",
    "    if adjusttxt:\n",
    "        kwargs = dict(transform=ax0.transAxes);\n",
    "        adjust_text(texts_ax0, ax=ax0, arrowprops=dict(arrowstyle=\"-\", color='k', lw=0.1), **kwargs);\n",
    "\n",
    "    if not((x_str == 'date') or ('index' in x_str) or (x_str == 'Location')):\n",
    "        ax0.set_xlim(left=100, right=None);\n",
    "        \n",
    "    # Show the plot lengend to link colors and polymer names\n",
    "    handles, labels = ax0.get_legend_handles_labels();\n",
    "    lgd = dict(zip(labels, handles));\n",
    "\n",
    "    if x_str == 'date':\n",
    "        locator = mdates.AutoDateLocator();#minticks=20, maxticks=24)\n",
    "        formatter = mdates.ConciseDateFormatter(locator)\n",
    "        ax0.xaxis.set_major_locator(locator)\n",
    "        ax0.xaxis.set_major_formatter(formatter)\n",
    "        fig.autofmt_xdate();\n",
    "    \n",
    "    if   x_str == \"index_confirmed\": ax0.set_xlabel(\"Days since 1000+ confirmed cases\" + r'$\\rightarrow$', fontsize=24);\n",
    "    elif x_str == \"index_deaths\":    ax0.set_xlabel(\"Days since 50+ deaths\" + r'$\\rightarrow$', fontsize=24);\n",
    "    elif x_str == \"index_recovered\": ax0.set_xlabel(\"Days since 2000+ recovered cases\" + r'$\\rightarrow$', fontsize=24);\n",
    "    elif x_str == \"index_active\":    ax0.set_xlabel(\"Days since 1000+ active cases\" + r'$\\rightarrow$', fontsize=24);\n",
    "    else:                            ax0.set_xlabel(x_str, fontsize=24);\n",
    "        \n",
    "    if y_str[0] == 'active':\n",
    "        ax0.set_ylabel(' / '.join(y_str) + ' [w/5 day estimate(s)]    ' + y_units, fontsize=24);\n",
    "    else:\n",
    "        ax0.set_ylabel(' / '.join(y_str) + '    ' + y_units, fontsize=24);\n",
    "\n",
    "#     ax0.spines['top'].set_visible(False);\n",
    "#     ax0.spines['right'].set_visible(False);\n",
    "\n",
    "    # Display main plot\n",
    "    if len(countries)<26: plt.legend(lgd.values(), lgd.keys(), prop={'size': 15}, loc=legPos);\n",
    "    plt.savefig(\n",
    "        'plt_' + x_str.replace(\" \", \"\") + '_vs_' + '_'.join(y_str).replace(\" \", \"\") + '.png',\n",
    "        dpi=200,\n",
    "        bbox_inches='tight'\n",
    "    );\n",
    "    plt.show();\n",
    "    mpl.rcParams.update(mpl.rcParamsDefault); # Recover matplotlib defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location, date, confirmed, deaths, recovered, active, new_confirmed, new_deaths, new_recovered, new_active, rate_of_growth, index\n",
    "\n",
    "x_str       = 'index_deaths'\n",
    "y_str       = [\"deaths\"];\n",
    "# countries   = ['Italy', 'Spain', 'China', 'India', 'Iran', 'Japan', 'Korea, South', 'Mexico', 'Norway', 'US'];\n",
    "countries   = ['Australia','Canada','China','China - Hong Kong','France','Germany','India','Iran','Italy','Japan','Korea, South','Mexico','Norway', 'New Zealand', 'Spain','Turkey','United Kingdom','US'];\n",
    "legPos      = \"bottom right\";\n",
    "xlogScale   = False\n",
    "ylogScale   = True;\n",
    "annotations = True;\n",
    "adjusttxt   = True;\n",
    "\n",
    "covid19plot(x_str, y_str, countries, legPos, xlogScale, ylogScale, annotations, adjusttxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_str       = 'index_recovered'\n",
    "y_str       = [\"recovered\"];\n",
    "# countries   = ['Italy', 'Spain', 'China', 'India', 'Iran', 'Japan', 'Korea, South', 'Mexico', 'Norway', 'US'];\n",
    "countries   = ['Australia','Canada','China','China - Hong Kong','France','Germany','India','Iran','Italy','Japan','Korea, South','Mexico','Norway', 'New Zealand', 'Spain','Turkey','United Kingdom','US'];\n",
    "legPos      = \"bottom right\";\n",
    "xlogScale   = False\n",
    "ylogScale   = True;\n",
    "annotations = True;\n",
    "adjusttxt   = True;\n",
    "\n",
    "covid19plot(x_str, y_str, countries, legPos, xlogScale, ylogScale, annotations, adjusttxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_str       = 'index_confirmed'\n",
    "y_str       = [\"confirmed\"];\n",
    "# countries   = ['Italy', 'Spain', 'China', 'India', 'Iran', 'Japan', 'Korea, South', 'Mexico', 'Norway', 'US'];\n",
    "countries   = ['Australia','Canada','China','China - Hong Kong','France','Germany','India','Iran','Italy','Japan','Korea, South','Mexico','Norway', 'New Zealand', 'Spain','Turkey','United Kingdom','US'];\n",
    "legPos      = \"bottom right\";\n",
    "xlogScale   = False\n",
    "ylogScale   = True;\n",
    "annotations = True;\n",
    "adjusttxt   = True;\n",
    "\n",
    "covid19plot(x_str, y_str, countries, legPos, xlogScale, ylogScale, annotations, adjusttxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_str       = 'index_active'\n",
    "y_str       = [\"active\"];\n",
    "# countries   = ['Italy', 'Spain', 'China', 'India', 'Iran', 'Japan', 'Korea, South', 'Mexico', 'Norway', 'US'];\n",
    "countries   = ['Australia','Canada','China','China - Hong Kong','France','Germany','India','Iran','Italy','Japan','Korea, South','Mexico','Norway', 'New Zealand', 'Spain','Turkey','United Kingdom','US'];\n",
    "legPos      = \"upper right\";\n",
    "xlogScale   = False\n",
    "ylogScale   = True;\n",
    "annotations = True;\n",
    "adjusttxt   = True;\n",
    "\n",
    "covid19plot(x_str, y_str, countries, legPos, xlogScale, ylogScale, annotations, adjusttxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_str       = 'date'\n",
    "y_str       = [\"confirmed\", \"active\", \"deaths\", \"recovered\"];\n",
    "countries   = ['Mexico'];\n",
    "legPos      = \"upper left\";\n",
    "xlogScale   = False\n",
    "ylogScale   = True;\n",
    "annotations = True;\n",
    "adjusttxt   = True;\n",
    "\n",
    "covid19plot(x_str, y_str, countries, legPos, xlogScale, ylogScale, annotations, adjusttxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_str       = 'date';\n",
    "y_str       = [\"new_active\", \"new_deaths\", \"new_recovered\"];\n",
    "countries   = ['Mexico'];\n",
    "legPos      = \"upper left\";\n",
    "xlogScale   = False;\n",
    "ylogScale   = True;\n",
    "annotations = True;\n",
    "adjusttxt   = True;\n",
    "\n",
    "covid19plot(x_str, y_str, countries, legPos, xlogScale, ylogScale, annotations, adjusttxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_str       = 'Location';\n",
    "y_str       = [\"rate_of_growth\"];\n",
    "countries   = ['Italy', 'Spain', 'China', 'India', 'Iran', 'Japan', 'Korea, South', 'Mexico', 'Norway', 'New Zealand', 'US'];\n",
    "legPos      = \"upper left\";\n",
    "xlogScale   = False;\n",
    "ylogScale   = True;\n",
    "annotations = True;\n",
    "adjusttxt   = True;\n",
    "\n",
    "covid19plot(x_str, y_str, countries, legPos, xlogScale, ylogScale, annotations, adjusttxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart the new confirmed cases of COVID-19 in the past week vs. the total confirmed cases to date.\n",
    "# When plotted in this way, exponential growth is represented as a straight line that slopes upwards.\n",
    "\n",
    "x_str = 'confirmed';\n",
    "y_str = ['new_confirmed'];\n",
    "\n",
    "# countries = []\n",
    "# for c in allcountries:\n",
    "#     if not(\" - \" in c):\n",
    "#         countries.append(c)\n",
    "\n",
    "countries   = ['Australia','Canada','China','China - Hong Kong','France','Germany','India','Iran','Italy','Japan','Korea, South','Mexico','Norway','New Zealand','Spain','Turkey','United Kingdom','US'];\n",
    "legPos      = 'upper left';\n",
    "xlogScale   = True;\n",
    "ylogScale   = True;\n",
    "annotations = True;\n",
    "adjusttxt   = True;\n",
    "\n",
    "covid19plot(x_str, y_str, countries, legPos, xlogScale, ylogScale, annotations, adjusttxt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
